### --------------- List of tags that are used to select a runner. --------------- ###
## Обязательный блок для запуска gitlab-ci. Определяет, на каких runner-ах будет запущен CI/CD путем выбора его с помощью tag'а. ##

default:
  tags:
  - bigdata
  - dmz
  - docker

### --------------- Defines a job stage. --------------- ###
## Stage .pre выполняется перед всем остальным кодом. stage .post выполняется после всего остального кода. ##
## Так же можо задать порядок выполнения stage-ов, указав их по порядку в этом блоке. ##

stages:
- .pre
- static analysis
- build
- unit_tests
- sonarqube_check
- push_pip
- build_and_publish_docs
- .post

### --------------- Include gitlab-ci-templates --------------- ###
## Добавляет в текущую конфигурацию CI\CD template's из DevOps репозитория для переиспользования. ##

include:
# VAULT
- project: DevOps/cicd-store/gitlabci/vault
  ref: v3
  file: .base_devops_get_cicd_secrets.yml

# DOCKER
- project: DevOps/cicd-store/gitlabci/docker
  ref: v4
  file: .base_docker_build.yml
- project: DevOps/cicd-store/gitlabci/docker
  ref: v4
  file: .base_docker_cleaner.yml

# SONARQUBE
- project: DevOps/cicd-store/gitlabci/sonarqube
  ref: v1
  file: .base_check_sonarqube.yml

### --------------- Get VAULT SECRET --------------- ###
## Переиспользование добавленного template'а по добавлению SSH-ключа пользователя ansible. ##
devops_get_cicd_secrets:
  extends: .base_devops_get_cicd_secrets

mypy:
  image: $CI_REGISTRY/platform/python:${PYTHON_VERSION}
  variables:
    PYTHON_VERSION: '3.7'
  stage: static analysis
  script:
  - pip3 install mypy pydantic
  - python3 -m mypy etl_entities

flake8:
  image: $CI_REGISTRY/platform/python:${PYTHON_VERSION}
  variables:
    PYTHON_VERSION: '3.7'
  stage: static analysis
  script:
  - pip3 install wemake-python-styleguide
  - python3 -m flake8 --format=default . 2>&1 | tee flake8.txt
  artifacts:
    when: always
    paths: [flake8.txt]

black:
  image: $CI_REGISTRY/platform/python:${PYTHON_VERSION}
  variables:
    PYTHON_VERSION: '3.7'
  stage: static analysis
  script:
  - pip3 install black
  - python3 -m black . --check

build_docker_image:
  extends: .base_docker_build
  stage: build
  variables:
    DOCKER_IMAGE_TAG: $CI_PIPELINE_ID
    DOCKER_BUILD_EXTRA_ARGS: --build-arg BUILD_NUMBER=$CI_PIPELINE_ID --build-arg BRANCH_NAME=$CI_COMMIT_BRANCH
    DOCKER_CACHE_FROM: $CI_REGISTRY/$CI_PROJECT_PATH:dev
  rules:
  - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    when: never
  - if: $CI_COMMIT_BRANCH =~ /^(dev|develop|master|main)$/
    variables:
      DOCKER_ADDITIONAL_TAGS: dev
  - if: $CI_COMMIT_TAG
    variables:
      DOCKER_IMAGE_TAG: $CI_COMMIT_TAG
      DOCKER_ADDITIONAL_TAGS: latest
  - when: on_success

run_unit_tests:
  image: ${CI_REGISTRY}/${CI_PROJECT_PATH}:${CI_PIPELINE_ID}
  stage: unit_tests
  variables:
    JUNIT_FILE: ${CI_PROJECT_DIR}/junitxml.xml
    COVERAGE_FILE: ${CI_PROJECT_DIR}/coverage.xml
  script:
  - pytest --verbose -s tests --cov-append --cov=etl_entities --cov-config=tests/.coveragerc --cov-report=xml:${COVERAGE_FILE} --junitxml=${JUNIT_FILE}
  after_script:
  - sed -i s/'\/app\/etl_entities'/'etl_entities'/ ${COVERAGE_FILE}
  artifacts:
    when: always
    paths:
    - ${COVERAGE_FILE}
    reports:
      junit:
      - ${JUNIT_FILE}
      cobertura:
      - ${COVERAGE_FILE}

sonarqube_check:
  extends: .base_check_sonarqube
  stage: sonarqube_check
  variables:
    SONAR_SOURCES: etl_entities

push_pip_repository:
  image: ${CI_REGISTRY}/${CI_PROJECT_PATH}:${CI_PIPELINE_ID}
  stage: push_pip
  only:
  - master
  - develop
  variables:
    GIT_STRATEGY: clone
    ARTIFACTORY_PYPI_REP: http://rep.msk.mts.ru/artifactory/api/pypi/pypi-local/
    TWINE_PASSWORD: ${USER_ARTIFACTORY_DOCKER_TOKEN}
    TWINE_USERNAME: ${USER_ARTIFACTORY_DOCKER_LOGIN}
  before_script:
  - pip3 install twine
  script:
  # Build /app/dist/etl-entities*.whl
  - python3 setup.py sdist bdist_wheel
  - python3 -m twine upload ./dist/* --repository-url ${ARTIFACTORY_PYPI_REP}

build_and_publish_docs:
  image: $CI_REGISTRY/platform/python:${PYTHON_VERSION}
  variables:
    PYTHON_VERSION: '3.7'
  stage: build_and_publish_docs
  only:
  - master
  - develop
  script:
  - pip3 install -r requirements-docs.txt && cd docs && make html && tar cvzf html-etl-entities-master.tar.gz -C _build/html .
  - curl -u "${USER_ARTIFACTORY_DOCKER_LOGIN}":"${USER_ARTIFACTORY_DOCKER_TOKEN}" -X PUT "${ARTIFACTORY_URL}/artifactory/files/onetools/etl-entities/docs/" -T html-etl-entities-master.tar.gz

clean_docker_repo:
  extends: .base_docker_cleaner
  stage: .post
  when: always
  variables:
    DOCKER_IMAGE_NAME: $CI_PROJECT_PATH
    DOCKER_IMAGE_TAGS: $CI_PIPELINE_ID
